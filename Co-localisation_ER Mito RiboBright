import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import tifffile
from scipy.stats import mannwhitneyu, bootstrap, pearsonr, wilcoxon
from skimage.filters import threshold_otsu

# --- Cropping parameters ---
CROP_X_START = 0
CROP_Y_START = 0
CROP_WIDTH = 2048
CROP_HEIGHT = 1024
CROP_X_END = CROP_X_START + CROP_WIDTH
CROP_Y_END = CROP_Y_START + CROP_HEIGHT

# --- Toggle visual inspection ---
VISUALIZE_RANDOM_SLICES = True

# --- Load image ---
def load_image_stack(path):
    with tifffile.TiffFile(path) as tif:
        data = tif.asarray()
        if data.ndim == 4:
            if data.shape[0] in [2, 3]:
                return data
            elif data.shape[1] in [2, 3]:
                return data.transpose(1, 0, 2, 3)
        raise ValueError(f"Unexpected data shape: {data.shape} in file: {path}")

# --- Compute Manders Coefficients ---
def compute_manders(ch1, ch2, plot=False, z=0, image_name=""):
    ch1 = ch1.astype(float)
    ch2 = ch2.astype(float)
    try:
        t1 = threshold_otsu(ch1)
        t2 = threshold_otsu(ch2)
    except ValueError:
        return 0, 0
    ch1_masked = np.where(ch1 > t1, ch1, 0)
    ch2_masked = np.where(ch2 > t2, ch2, 0)
    mask = (ch1_masked > 0) | (ch2_masked > 0)
    ch1_vals = ch1_masked[mask]
    ch2_vals = ch2_masked[mask]
    if np.sum(ch1_vals) == 0 or np.sum(ch2_vals) == 0:
        return 0, 0
    M1 = np.sum(ch1_vals[ch2_vals > 0]) / np.sum(ch1_vals)
    M2 = np.sum(ch2_vals[ch1_vals > 0]) / np.sum(ch2_vals)
    if plot:
        fig, axs = plt.subplots(1, 2, figsize=(10, 5))
        axs[0].imshow(ch1_masked, cmap="Reds")
        axs[0].set_title(f"RB (Otsu={t1:.1f})")
        axs[1].imshow(ch2_masked, cmap="Greens")
        axs[1].set_title(f"Target (Otsu={t2:.1f})")
        plt.suptitle(f"{image_name} - Z={z}")
        plt.tight_layout()
        plt.show()
    return M1, M2

# --- Compute Pearson Correlation (Unthresholded) ---
def compute_pearson(ch1, ch2):
    ch1_flat = ch1.flatten().astype(float)
    ch2_flat = ch2.flatten().astype(float)
    mask = (ch1_flat > 0) | (ch2_flat > 0)
    if np.count_nonzero(mask) < 2:
        return np.nan
    r, _ = pearsonr(ch1_flat[mask], ch2_flat[mask])
    return r

# --- Compute Pearson Correlation (Thresholded using Otsu) ---
def compute_pearson_thresholded(ch1, ch2):
    ch1 = ch1.astype(float)
    ch2 = ch2.astype(float)
    try:
        t1 = threshold_otsu(ch1)
        t2 = threshold_otsu(ch2)
    except ValueError:
        return np.nan
    mask = (ch1 > t1) | (ch2 > t2)
    if np.count_nonzero(mask) < 2:
        return np.nan
    r, _ = pearsonr(ch1[mask], ch2[mask])
    return r

output_dir = "/Volumes/bifchem/Projects Hansen/Lab Members folders/XH/RiboBright/RB_XH_017/plots"
os.makedirs(output_dir, exist_ok=True)

# --- Compute Pearson Correlation (Thresholded using Costes) ---
def compute_pearson_costes(ch1, ch2, n_random=100, alpha=0.05):
    ch1 = ch1.astype(float)
    ch2 = ch2.astype(float)
    ch1_flat = ch1.flatten()
    ch2_flat = ch2.flatten()

    mask = (ch1_flat > 0) | (ch2_flat > 0)
    if np.count_nonzero(mask) < 2:
        return np.nan
    r_actual, _ = pearsonr(ch1_flat[mask], ch2_flat[mask])  # kept if you want to inspect

    rand_rs = []
    for _ in range(n_random):
        ch2_rand = np.random.permutation(ch2_flat)
        rand_r, _ = pearsonr(ch1_flat[mask], ch2_rand[mask])
        rand_rs.append(rand_r)

    threshold_r = np.percentile(rand_rs, 100 * (1 - alpha))

    thresholds = np.linspace(np.min(ch1_flat), np.max(ch1_flat), num=100)
    for t in thresholds:
        m = (ch1_flat > t) & (ch2_flat > t)
        if np.count_nonzero(m) < 2:
            continue
        r_test, _ = pearsonr(ch1_flat[m], ch2_flat[m])
        if r_test > threshold_r:
            return r_test
    return np.nan

# --- Analyze images ---
def analyze_folder(experiment_path, experiment_label):
    results = []
    for group in ['RB_ER', 'RB_Mito']:
        group_path = os.path.join(experiment_path, group)
        for subdir, _, files in os.walk(group_path):
            for file in tqdm(files, desc=f"{experiment_label} - {group}"):
                if not file.endswith('.ome.tif') or file.startswith("._"):
                    continue
                filepath = os.path.join(subdir, file)
                try:
                    data = load_image_stack(filepath)
                    num_channels, num_z = data.shape[:2]
                    if experiment_label == 'RB_XH_017':
                        if num_channels != 2:
                            raise ValueError(f"Expected 2 channels for RB_XH_017, got {num_channels}")
                        rb_ch, target_ch = 0, 1
                    else:
                        rb_ch = 0
                        target_ch = 1 if group == 'RB_ER' else 2
                    m1s, m2s, pearsons, pearsons_thresh = [], [], [], []
                    for z in range(num_z):
                        rb = data[rb_ch, z]
                        target = data[target_ch, z]
                        rb_crop = rb[CROP_Y_START:CROP_Y_END, CROP_X_START:CROP_X_END]
                        target_crop = target[CROP_Y_START:CROP_Y_END, CROP_X_START:CROP_X_END]
                        show_plot = VISUALIZE_RANDOM_SLICES and z == 0 and np.random.rand() < 0.03
                        m1, m2 = compute_manders(rb_crop, target_crop, plot=show_plot, z=z, image_name=file)
                        r_unthresh = compute_pearson(rb_crop, target_crop)
                        r_thresh = compute_pearson_thresholded(rb_crop, target_crop)
                        r_costes = compute_pearson_costes(rb_crop, target_crop)
                        m1s.append(m1)
                        m2s.append(m2)
                        pearsons.append(r_unthresh)
                        pearsons_thresh.append(r_thresh)
                    results.append({
                        "Experiment": experiment_label,
                        "Group": group,
                        "Image": file,
                        "M1": np.mean(m1s),
                        "M2": np.mean(m2s),
                        "Pearson": np.nanmean(pearsons),
                        "Pearson_Thresholded": np.nanmean(pearsons_thresh),
                        "Pearson_Costes": r_costes
                    })

                except Exception as e:
                    print(f"Failed: {filepath}\nError: {e}")
    return results

experiment_roots = {
    "RB_XH_013": "/Volumes/bifchem/Projects Hansen/Lab Members folders/XH/RiboBright/RB_XH_013",
    "RB_XH_017": "/Volumes/bifchem/Projects Hansen/Lab Members folders/XH/RiboBright/RB_XH_017"
}

all_results = []
for label, path in experiment_roots.items():
    print(f"Analyzing {label}...")
    all_results.extend(analyze_folder(path, label))

df = pd.DataFrame(all_results)

# === Save the requested summary CSV (before plotting) ===
summary_cols = ["Experiment", "Group", "Image", "M1", "M2", "Pearson"]
df_summary = df[summary_cols].copy()
summary_path = os.path.join(output_dir, "image_analysis_summary.csv")
df_summary.to_csv(summary_path, index=False)
print(f"Saved summary to: {summary_path}")

# Also keep your original, more detailed CSV if you want
df.to_csv(os.path.join(output_dir, "manders_results.csv"), index=False)

# --- Statistical Functions ---
def cohens_d(x, y):
    nx, ny = len(x), len(y)
    pooled_std = np.sqrt(((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / (nx + ny - 2))
    return (np.mean(x) - np.mean(y)) / pooled_std

def median_ci(data, confidence=0.95, n_resamples=10000):
    res = bootstrap((data,), np.median, confidence_level=confidence, n_resamples=n_resamples, method='basic')
    return res.confidence_interval.low, res.confidence_interval.high

# --- Plotting ---
sns.set(style="white", font_scale=1.2)
palette = {"RB_XH_013": "#1f77b4", "RB_XH_017": "#ff7f0e"}

for metric in ["M1", "M2", "Pearson", "Pearson_Thresholded", "Pearson_Costes"]:
    plt.figure(figsize=(10, 6))
    ax = sns.violinplot(x="Group", y=metric, data=df, inner="box", palette="pastel", cut=0)
    sns.stripplot(x="Group", y=metric, data=df, hue="Experiment", palette=palette, dodge=True, jitter=True, size=6, edgecolor="gray", linewidth=0.7)

    er_vals = df[df["Group"] == "RB_ER"][metric].dropna()
    mito_vals = df[df["Group"] == "RB_Mito"][metric].dropna()

    # Stats
    stat, pval = mannwhitneyu(er_vals, mito_vals, alternative='two-sided')
    effect_size = cohens_d(er_vals, mito_vals)

    median_er, median_mito = np.median(er_vals), np.median(mito_vals)
    mean_er, mean_mito = np.mean(er_vals), np.mean(mito_vals)

    ci_er, ci_mito = median_ci(er_vals), median_ci(mito_vals)

    fc_med = (median_er / median_mito) if median_mito != 0 else np.nan
    fc_mean = (mean_er / mean_mito) if mean_mito != 0 else np.nan

    print(f"\n{metric}: ER median = {median_er:.3f} (CI: {ci_er}), "
          f"Mito median = {median_mito:.3f} (CI: {ci_mito}), "
          f"Median FC = {fc_med:.2f}, Mean FC = {fc_mean:.2f}, "
          f"p (Mann-Whitney U) = {pval:.2e}, d = {effect_size:.2f}")

    max_y = max(df[metric].dropna()) + 0.05
    ax.plot([0, 1], [max_y, max_y], lw=1.5, color='black')
    ax.text(0.5, max_y + 0.01,
            f"Test: Mann-Whitney U\n"
            f"p = {pval:.2e}\n"
            f"FC (mean) = {fc_mean:.2f}\n"
            f"FC (median) = {fc_med:.2f}\n"
            f"d = {effect_size:.2f}",
            ha='center', fontsize=11)

    for i, (group, med, ci) in enumerate(zip(["RB_ER", "RB_Mito"], [median_er, median_mito], [ci_er, ci_mito])):
        ax.text(i, med + 0.01, f"Median: {med:.2f}\nCI: [{ci[0]:.2f}, {ci[1]:.2f}]", ha='center', va='bottom', fontsize=10)

    plt.title(f"{metric} Co-localization (ER vs. Mito)")
    plt.ylabel(f"{metric} coefficient")
    plt.xlabel("Group")
    plt.legend(title="Experiment", loc="upper right")
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{metric.lower()}_violin.svg"), dpi=300)
    plt.show()

# --- M1 vs M2 per group ---
for group in ["RB_ER", "RB_Mito"]:
    plt.figure(figsize=(6, 6))
    subset = df[df["Group"] == group][["M1", "M2"]].dropna()
    melted = pd.melt(subset.reset_index(drop=True), value_vars=["M1", "M2"], var_name="Metric", value_name="Manders")
    ax = sns.violinplot(x="Metric", y="Manders", data=melted, inner="box", palette="pastel", cut=0)
    sns.stripplot(x="Metric", y="Manders", data=melted, jitter=True, size=6, color="gray", alpha=0.6)

    # Paired stats
    stat, pval = wilcoxon(subset["M1"], subset["M2"])
    m1_med = np.median(subset["M1"]); m2_med = np.median(subset["M2"])
    m1_mean = np.mean(subset["M1"]);  m2_mean = np.mean(subset["M2"])

    fc_med = (m1_med / m2_med) if m2_med != 0 else np.nan
    fc_mean = (m1_mean / m2_mean) if m2_mean != 0 else np.nan

    max_y = melted["Manders"].max() + 0.05
    ax.plot([0, 1], [max_y, max_y], lw=1.5, color='black')
    ax.text(0.5, max_y + 0.01,
            f"Test: Wilcoxon signed-rank\n"
            f"p = {pval:.3e}\n"
            f"FC (mean) = {fc_mean:.2f}\n"
            f"FC (median) = {fc_med:.2f}\n"
            f"med M1 = {m1_med:.3f}\n"
            f"med M2 = {m2_med:.3f}",
            ha='center', fontsize=10)

    plt.title(f"{group}: M1 vs M2")
    plt.ylabel("Manders Coefficient")
    plt.xlabel("")
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"manders_{group}_M1_vs_M2_violin.svg"), dpi=300)
    plt.show()
